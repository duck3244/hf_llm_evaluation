"""
ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ
README ì˜ˆì‹œì™€ ì¼ì¹˜í•˜ë„ë¡ ìˆ˜ì •ëœ SQLite ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ ê¸°ëŠ¥
"""

import sqlite3
import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional, Any, Tuple
import json
from datetime import datetime
import logging

from ..models.data_models import (
    ModelInfo, EvaluationResult, TaskCategory, CollectionStats,
    serialize_for_db, deserialize_from_db
)
from ..utils.logger import get_logger, log_database_operation

logger = get_logger(__name__)


class DatabaseError(Exception):
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì˜ˆì™¸"""
    pass


class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤ (README ì˜ˆì‹œ êµ¬í˜„)"""

    def __init__(self, db_path: str = "data/llm_evaluations.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”: {self.db_path}")
        self.init_database()

    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë° í…Œì´ë¸” ì´ˆê¸°í™” (README ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ëª¨ë¸ ì •ë³´ í…Œì´ë¸” (README ëª¨ë¸ ì •ë³´ êµ¬í˜„)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS models (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        model_id TEXT UNIQUE NOT NULL,
                        model_name TEXT,
                        author TEXT,
                        downloads INTEGER DEFAULT 0,
                        likes INTEGER DEFAULT 0,
                        created_at TEXT,
                        last_modified TEXT,
                        library_name TEXT,
                        pipeline_tag TEXT,
                        tags TEXT,
                        task_categories TEXT,
                        model_size TEXT,
                        license TEXT,
                        collected_at TEXT DEFAULT CURRENT_TIMESTAMP,
                        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # í‰ê°€ ê²°ê³¼ í…Œì´ë¸” (README í‰ê°€ ë°ì´í„° êµ¬í˜„)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS evaluations (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        model_id TEXT NOT NULL,
                        dataset_name TEXT,
                        metric_name TEXT,
                        metric_value REAL,
                        task_type TEXT,
                        evaluation_date TEXT,
                        dataset_version TEXT,
                        metric_config TEXT,
                        additional_info TEXT,
                        verified BOOLEAN DEFAULT FALSE,
                        collected_at TEXT DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (model_id) REFERENCES models (model_id)
                    )
                """)

                # íƒœìŠ¤í¬ ì¹´í…Œê³ ë¦¬ í…Œì´ë¸” (README íƒœìŠ¤í¬ í…Œì´ë¸” êµ¬í˜„)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS task_categories (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        task_name TEXT UNIQUE NOT NULL,
                        description TEXT,
                        common_datasets TEXT,
                        common_metrics TEXT,
                        subcategories TEXT,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # ë°ì´í„°ì…‹ ì •ë³´ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS datasets (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        dataset_name TEXT UNIQUE NOT NULL,
                        task_type TEXT,
                        description TEXT,
                        size INTEGER,
                        language TEXT,
                        splits TEXT,
                        metrics TEXT,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # ìˆ˜ì§‘ í†µê³„ í…Œì´ë¸” (README í†µê³„ êµ¬í˜„)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS collection_stats (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        collection_date TEXT,
                        total_models INTEGER DEFAULT 0,
                        total_evaluations INTEGER DEFAULT 0,
                        tasks_collected TEXT,
                        collection_duration REAL,
                        errors_count INTEGER DEFAULT 0,
                        success_rate REAL DEFAULT 0.0,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±
                indexes = [
                    "CREATE INDEX IF NOT EXISTS idx_models_pipeline_tag ON models (pipeline_tag)",
                    "CREATE INDEX IF NOT EXISTS idx_models_downloads ON models (downloads DESC)",
                    "CREATE INDEX IF NOT EXISTS idx_models_author ON models (author)",
                    "CREATE INDEX IF NOT EXISTS idx_evaluations_model_id ON evaluations (model_id)",
                    "CREATE INDEX IF NOT EXISTS idx_evaluations_task_type ON evaluations (task_type)",
                    "CREATE INDEX IF NOT EXISTS idx_evaluations_metric ON evaluations (metric_name)",
                    "CREATE INDEX IF NOT EXISTS idx_evaluations_value ON evaluations (metric_value DESC)"
                ]

                for index_sql in indexes:
                    cursor.execute(index_sql)

                conn.commit()
                logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ë° ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

        except sqlite3.Error as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise DatabaseError(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def insert_model(self, model_info: ModelInfo) -> bool:
        """ëª¨ë¸ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (README ì˜ˆì‹œ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT OR REPLACE INTO models 
                    (model_id, model_name, author, downloads, likes, created_at, 
                     last_modified, library_name, pipeline_tag, tags, task_categories,
                     model_size, license, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    model_info.model_id,
                    model_info.model_name,
                    model_info.author,
                    model_info.downloads,
                    model_info.likes,
                    model_info.created_at,
                    model_info.last_modified,
                    model_info.library_name,
                    model_info.pipeline_tag,
                    serialize_for_db(model_info.tags),
                    serialize_for_db(model_info.task_categories),
                    model_info.model_size,
                    model_info.license,
                    datetime.now().isoformat()
                ))

                conn.commit()
                log_database_operation("INSERT", "models", 1, logger)
                logger.debug(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_info.model_id}")
                return True

        except sqlite3.Error as e:
            logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨ ({model_info.model_id}): {e}")
            return False

    def insert_evaluation(self, evaluation: EvaluationResult) -> bool:
        """í‰ê°€ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (README ì˜ˆì‹œ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT INTO evaluations 
                    (model_id, dataset_name, metric_name, metric_value, 
                     task_type, evaluation_date, dataset_version, metric_config,
                     additional_info, verified)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    evaluation.model_id,
                    evaluation.dataset_name,
                    evaluation.metric_name,
                    evaluation.metric_value,
                    evaluation.task_type,
                    evaluation.evaluation_date,
                    evaluation.dataset_version,
                    serialize_for_db(evaluation.metric_config),
                    serialize_for_db(evaluation.additional_info),
                    evaluation.verified
                ))

                conn.commit()
                log_database_operation("INSERT", "evaluations", 1, logger)
                logger.debug(f"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {evaluation.model_id} - {evaluation.metric_name}")
                return True

        except sqlite3.Error as e:
            logger.error(f"âŒ í‰ê°€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def insert_task_category(self, task_category: TaskCategory) -> bool:
        """íƒœìŠ¤í¬ ì¹´í…Œê³ ë¦¬ ì •ë³´ ì €ì¥ (README íƒœìŠ¤í¬ í…Œì´ë¸” êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT OR REPLACE INTO task_categories 
                    (task_name, description, common_datasets, common_metrics, subcategories)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    task_category.task_name,
                    task_category.description,
                    serialize_for_db(task_category.common_datasets),
                    serialize_for_db(task_category.common_metrics),
                    serialize_for_db(task_category.subcategories)
                ))

                conn.commit()
                log_database_operation("INSERT", "task_categories", 1, logger)
                return True

        except sqlite3.Error as e:
            logger.error(f"âŒ íƒœìŠ¤í¬ ì¹´í…Œê³ ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_models_by_task(self, task: str, limit: Optional[int] = None) -> pd.DataFrame:
        """íŠ¹ì • íƒœìŠ¤í¬ì˜ ëª¨ë¸ë“¤ì„ ì¡°íšŒ (README ì˜ˆì‹œ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = """
                    SELECT * FROM models 
                    WHERE pipeline_tag = ? OR task_categories LIKE ?
                    ORDER BY downloads DESC
                """
                params = [task, f'%{task}%']

                if limit:
                    query += " LIMIT ?"
                    params.append(limit)

                df = pd.read_sql_query(query, conn, params=params)

                # JSON ì»¬ëŸ¼ ì—­ì§ë ¬í™”
                if not df.empty:
                    df['tags'] = df['tags'].apply(lambda x: deserialize_from_db(x, list) if x else [])
                    df['task_categories'] = df['task_categories'].apply(
                        lambda x: deserialize_from_db(x, list) if x else [])

                logger.debug(f"ğŸ“Š íƒœìŠ¤í¬ '{task}' ëª¨ë¸ ì¡°íšŒ: {len(df)}ê°œ")
                return df

        except sqlite3.Error as e:
            logger.error(f"âŒ ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def get_evaluations_by_model(self, model_id: str) -> pd.DataFrame:
        """íŠ¹ì • ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ë¥¼ ì¡°íšŒ (README ì˜ˆì‹œ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = "SELECT * FROM evaluations WHERE model_id = ? ORDER BY collected_at DESC"
                df = pd.read_sql_query(query, conn, params=[model_id])

                # JSON ì»¬ëŸ¼ ì—­ì§ë ¬í™”
                if not df.empty:
                    df['additional_info'] = df['additional_info'].apply(
                        lambda x: deserialize_from_db(x, dict) if x else {}
                    )
                    df['metric_config'] = df['metric_config'].apply(
                        lambda x: deserialize_from_db(x, dict) if x else {}
                    )

                logger.debug(f"ğŸ“Š ëª¨ë¸ '{model_id}' í‰ê°€ ê²°ê³¼ ì¡°íšŒ: {len(df)}ê°œ")
                return df

        except sqlite3.Error as e:
            logger.error(f"âŒ í‰ê°€ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def get_task_leaderboard(self, task_type: str, metric_name: str,
                             dataset_name: Optional[str] = None, limit: int = 50) -> pd.DataFrame:
        """íƒœìŠ¤í¬ë³„ ë¦¬ë”ë³´ë“œë¥¼ ìƒì„± (README ë¦¬ë”ë³´ë“œ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = """
                    SELECT m.model_id, m.model_name, m.author, e.metric_value, 
                           e.dataset_name, e.evaluation_date, m.downloads, m.likes,
                           m.model_size, m.license, e.verified
                    FROM models m
                    JOIN evaluations e ON m.model_id = e.model_id
                    WHERE e.task_type = ? AND e.metric_name = ?
                """
                params = [task_type, metric_name]

                if dataset_name:
                    query += " AND e.dataset_name = ?"
                    params.append(dataset_name)

                query += " ORDER BY e.metric_value DESC LIMIT ?"
                params.append(limit)

                df = pd.read_sql_query(query, conn, params=params)
                logger.debug(f"ğŸ† ë¦¬ë”ë³´ë“œ ìƒì„±: {task_type}-{metric_name} ({len(df)}ê°œ)")
                return df

        except sqlite3.Error as e:
            logger.error(f"âŒ ë¦¬ë”ë³´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def get_model_statistics(self) -> Dict[str, Any]:
        """ëª¨ë¸ í†µê³„ ì •ë³´ ë°˜í™˜ (README í†µê³„ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ì „ì²´ ëª¨ë¸ ìˆ˜
                cursor.execute("SELECT COUNT(*) FROM models")
                total_models = cursor.fetchone()[0]

                # íƒœìŠ¤í¬ë³„ ëª¨ë¸ ìˆ˜
                cursor.execute("""
                    SELECT pipeline_tag, COUNT(*) 
                    FROM models 
                    WHERE pipeline_tag IS NOT NULL AND pipeline_tag != ''
                    GROUP BY pipeline_tag 
                    ORDER BY COUNT(*) DESC
                """)
                task_counts = dict(cursor.fetchall())

                # í‰ê°€ ê²°ê³¼ ìˆ˜
                cursor.execute("SELECT COUNT(*) FROM evaluations")
                total_evaluations = cursor.fetchone()[0]

                # ìµœê·¼ ìˆ˜ì§‘ ë‚ ì§œ
                cursor.execute("SELECT MAX(collected_at) FROM models")
                last_collection = cursor.fetchone()[0]

                # ìƒìœ„ ì‘ì„±ì
                cursor.execute("""
                    SELECT author, COUNT(*) as model_count
                    FROM models 
                    WHERE author IS NOT NULL AND author != ''
                    GROUP BY author 
                    ORDER BY model_count DESC 
                    LIMIT 5
                """)
                top_authors = dict(cursor.fetchall())

                stats = {
                    'total_models': total_models,
                    'total_evaluations': total_evaluations,
                    'task_counts': task_counts,
                    'last_collection': last_collection,
                    'top_authors': top_authors
                }

                logger.debug(f"ğŸ“Š í†µê³„ ì¡°íšŒ ì™„ë£Œ: {total_models:,}ê°œ ëª¨ë¸, {total_evaluations:,}ê°œ í‰ê°€")
                return stats

        except sqlite3.Error as e:
            logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def search_models(self, query: str, limit: int = 50) -> pd.DataFrame:
        """ëª¨ë¸ ê²€ìƒ‰ (README ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                sql_query = """
                    SELECT * FROM models 
                    WHERE model_id LIKE ? OR model_name LIKE ? OR author LIKE ?
                    ORDER BY downloads DESC
                    LIMIT ?
                """
                search_term = f"%{query}%"
                params = [search_term, search_term, search_term, limit]

                df = pd.read_sql_query(sql_query, conn, params=params)
                logger.debug(f"ğŸ” ëª¨ë¸ ê²€ìƒ‰ '{query}': {len(df)}ê°œ ê²°ê³¼")
                return df

        except sqlite3.Error as e:
            logger.error(f"âŒ ëª¨ë¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def get_top_models_by_downloads(self, limit: int = 50, task: Optional[str] = None) -> pd.DataFrame:
        """ë‹¤ìš´ë¡œë“œ ìˆ˜ ê¸°ì¤€ ìƒìœ„ ëª¨ë¸ (README ìƒìœ„ ëª¨ë¸ í‘œ êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = "SELECT * FROM models"
                params = []

                if task:
                    query += " WHERE pipeline_tag = ?"
                    params.append(task)

                query += " ORDER BY downloads DESC LIMIT ?"
                params.append(limit)

                df = pd.read_sql_query(query, conn, params=params)
                logger.debug(f"ğŸ† ìƒìœ„ ëª¨ë¸ ì¡°íšŒ: {len(df)}ê°œ")
                return df

        except sqlite3.Error as e:
            logger.error(f"âŒ ìƒìœ„ ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def export_to_csv(self, output_dir: str = "exports"):
        """ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸° (README ë‚´ë³´ë‚´ê¸° êµ¬í˜„)"""
        try:
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)

            exported_files = []

            with sqlite3.connect(self.db_path) as conn:
                # ëª¨ë¸ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                models_df = pd.read_sql_query("SELECT * FROM models ORDER BY downloads DESC", conn)
                if not models_df.empty:
                    models_file = output_path / "models.csv"
                    models_df.to_csv(models_file, index=False, encoding='utf-8')
                    exported_files.append(str(models_file))

                # í‰ê°€ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                evaluations_df = pd.read_sql_query("SELECT * FROM evaluations ORDER BY collected_at DESC", conn)
                if not evaluations_df.empty:
                    evaluations_file = output_path / "evaluations.csv"
                    evaluations_df.to_csv(evaluations_file, index=False, encoding='utf-8')
                    exported_files.append(str(evaluations_file))

                # íƒœìŠ¤í¬ ì¹´í…Œê³ ë¦¬ ë‚´ë³´ë‚´ê¸°
                tasks_df = pd.read_sql_query("SELECT * FROM task_categories", conn)
                if not tasks_df.empty:
                    tasks_file = output_path / "task_categories.csv"
                    tasks_df.to_csv(tasks_file, index=False, encoding='utf-8')
                    exported_files.append(str(tasks_file))

                # ìˆ˜ì§‘ í†µê³„ ë‚´ë³´ë‚´ê¸°
                stats_df = pd.read_sql_query("SELECT * FROM collection_stats ORDER BY created_at DESC", conn)
                if not stats_df.empty:
                    stats_file = output_path / "collection_stats.csv"
                    stats_df.to_csv(stats_file, index=False, encoding='utf-8')
                    exported_files.append(str(stats_file))

            logger.info(f"ğŸ“ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {len(exported_files)}ê°œ íŒŒì¼")
            for file_path in exported_files:
                logger.info(f"   â€¢ {file_path}")

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")

    def backup_database(self, backup_path: Optional[str] = None):
        """ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (README ë¬¸ì œ í•´ê²° êµ¬í˜„)"""
        if not backup_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = f"data/backup_llm_evaluations_{timestamp}.db"

        try:
            import shutil
            backup_path_obj = Path(backup_path)
            backup_path_obj.parent.mkdir(parents=True, exist_ok=True)

            shutil.copy2(self.db_path, backup_path)
            logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ: {backup_path}")
            return backup_path
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹¤íŒ¨: {e}")
            return None

    def vacuum_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” (README ì„±ëŠ¥ ìµœì í™” êµ¬í˜„)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                logger.info("ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                conn.execute("VACUUM")
                conn.execute("ANALYZE")
                logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ")
        except sqlite3.Error as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")

    def get_database_size(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ì •ë³´ ì¡°íšŒ"""
        try:
            file_size = self.db_path.stat().st_size
            size_mb = file_size / (1024 * 1024)

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜
                tables = ['models', 'evaluations', 'task_categories', 'collection_stats']
                table_counts = {}

                for table in tables:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    table_counts[table] = cursor.fetchone()[0]

            return {
                'file_size_bytes': file_size,
                'file_size_mb': round(size_mb, 2),
                'table_counts': table_counts,
                'db_path': str(self.db_path)
            }

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ (README ë¦¬ì†ŒìŠ¤ ì •ë¦¬ êµ¬í˜„)"""
        logger.debug("ğŸ”’ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì ì¢…ë£Œ")

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.close()